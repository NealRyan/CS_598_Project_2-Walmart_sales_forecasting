{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import patsy\n",
    "\n",
    "# Set seed\n",
    "np.random.seed(4031)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data file locations and names\n",
    "\n",
    "project_root_dir = \"Data\"\n",
    "project_subdir_prefix = \"fold_\"\n",
    "train_data_filename = \"train.csv\"\n",
    "test_data_filename = \"test.csv\"\n",
    "\n",
    "\n",
    "# The number of train/test data folders and the target RMSE for each\n",
    "# train/test split in each folder\n",
    "\n",
    "n_datasets = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of data subfolders, each with a separate training and test set.\n",
    "# fold1 - fold5 have target RMSE 0.125, and fold6 - fold10 have target RMSE 0.135.\n",
    "\n",
    "os_walk = os.walk(project_root_dir)\n",
    "data_subdir_list = [subdirs for root, subdirs, files in os_walk][0]\n",
    "n_subdirs = len(data_subdir_list)\n",
    "\n",
    "assert(n_subdirs == n_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists for training and test datasets\n",
    "\n",
    "train_datasets = []\n",
    "test_datasets = []\n",
    "\n",
    "\n",
    "# Loop over subfolders and read in training/test datasets and test house sale prices.\n",
    "# Use a loop instead of using os.walk directly to avoid \"fold10\" immediately following \"fold1\".\n",
    "\n",
    "for subdir_num in np.arange(n_subdirs) + 1:\n",
    "    subdir_num_str = str(subdir_num)\n",
    "    train_datasets.append(pd.read_csv(os.path.join(project_root_dir,\n",
    "                                                   project_subdir_prefix + subdir_num_str,\n",
    "                                                   train_data_filename)))\n",
    "    test_datasets.append(pd.read_csv(os.path.join(project_root_dir,\n",
    "                                                   project_subdir_prefix + subdir_num_str,\n",
    "                                                   test_data_filename)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Scoring function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a WMAE function for scoring\n",
    "\n",
    "def wmae():\n",
    "    file_path = 'Data/test_with_label.csv'\n",
    "    test = pd.read_csv(file_path)\n",
    "    num_folds = 10\n",
    "    wae = []\n",
    "\n",
    "    for i in range(num_folds):\n",
    "        file_path = f'Data/fold_{i+1}/mypred.csv'\n",
    "        test_pred = pd.read_csv(file_path)\n",
    "\n",
    "        # Left join with the test data\n",
    "        new_test = test_pred.merge(test, on=['Date', 'Store', 'Dept'], how='left')\n",
    "\n",
    "        # Compute the Weighted Absolute Error\n",
    "        actuals = new_test['Weekly_Sales']\n",
    "        preds = new_test['Weekly_Pred']\n",
    "        weights = new_test['IsHoliday'].apply(lambda x: 5 if x else 1)\n",
    "        wae.append(sum(weights * abs(actuals - preds)) / sum(weights))\n",
    "\n",
    "    return wae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop through data and pull apart date into week and year\n",
    "def preprocess(data):\n",
    "    #Split date into useful features\n",
    "    tmp = pd.to_datetime(data['Date'])\n",
    "    data['Wk'] = tmp.dt.isocalendar().week\n",
    "    data['Yr'] = tmp.dt.year\n",
    "    data['Wk'] = pd.Categorical(data['Wk'], categories=[i for i in range(1, 53)])  # 52 weeks \n",
    "\n",
    "    #One hot encode Wk\n",
    "    data = pd.get_dummies(data, columns=['Wk'], prefix='Week')\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD Implementation (not working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(n_datasets):\n",
    "    train = train_datasets[j]\n",
    "    test = test_datasets[j]\n",
    "\n",
    "    # Initialize the DataFrame to store predictions\n",
    "    test_pred = pd.DataFrame()\n",
    "\n",
    "    fold_train = preprocess(train)\n",
    "    fold_test = preprocess(test)\n",
    "\n",
    "    stores = fold_train[\"Store\"].unique()\n",
    "    depts = fold_train[\"Dept\"].unique()\n",
    "    years = fold_train[\"Yr\"].unique()\n",
    "\n",
    "    for store in stores:\n",
    "        for dept in depts:\n",
    "            for year in years:\n",
    "                #Find training and test data within same store and then same department\n",
    "                train = fold_train[(fold_train[\"Store\"] == store) & (fold_train[\"Dept\"] == dept) & (fold_train[\"Yr\"] == year)]\n",
    "                test = fold_test[(fold_test[\"Store\"] == store) & (fold_test[\"Dept\"] == dept) & (fold_test[\"Yr\"] == year)]\n",
    "\n",
    "                #abort if the train data is non-existant (i.e., this combo of store/dept doesnt appear in data)\n",
    "                if len(train) == 0:\n",
    "                    continue\n",
    "\n",
    "                Y_train = train[\"Weekly_Sales\"]\n",
    "                X_train = train.drop([\"Weekly_Sales\", \"Date\"], axis=1)\n",
    "\n",
    "                X_test = test\n",
    "\n",
    "                #Keep Store, dept, and date info for later merging\n",
    "                tmp_pred = X_test[['Store', 'Dept', 'Date']]\n",
    "                X_test = X_test.drop([\"Date\"], axis=1)\n",
    "\n",
    "\n",
    "                #Implement SVD\n",
    "                #n_components=5\n",
    "                #svd_df = pd.DataFrame(svd_result, columns=[[f'SVD_{i}' for i in range (n_components)]]) \n",
    "                svd = TruncatedSVD() \n",
    "                svd_result = svd.fit_transform(X_train)\n",
    "                svd_df = pd.DataFrame(svd_result) \n",
    "\n",
    "                #Train model on only the features SVD selected\n",
    "                model = sm.OLS(Y_train, svd_df).fit()\n",
    "                mycoef = model.params.fillna(0)\n",
    "                \n",
    "                #Fit SVD columns for test set\n",
    "                X_test = svd.transform(X_test)\n",
    "                \n",
    "                #Predict Y\n",
    "                tmp_pred['Weekly_Pred'] = np.dot(X_test, mycoef)\n",
    "\n",
    "                #Readd context of store, dept, and date\n",
    "                test_pred = pd.concat([test_pred, tmp_pred], ignore_index=True)\n",
    "            \n",
    "        \n",
    "    test_pred['Weekly_Pred'].fillna(0, inplace=True)\n",
    "    # Save the output to CSV\n",
    "    file_path = f'Data/fold_{j+1}/mypred.csv'\n",
    "    print(f'fold_{j+1} processed')\n",
    "    test_pred.to_csv(file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Refactor (not working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(n_datasets):\n",
    "    train = train_datasets[j]\n",
    "    test = test_datasets[j]\n",
    "\n",
    "    # Initialize the DataFrame to store predictions\n",
    "    test_pred = pd.DataFrame()\n",
    "\n",
    "    fold_train = preprocess(train)\n",
    "    fold_test = preprocess(test)\n",
    "\n",
    "    stores = fold_train[\"Store\"].unique()\n",
    "    depts = fold_train[\"Dept\"].unique()\n",
    "    years = fold_train[\"Yr\"].unique()\n",
    "\n",
    "    for store in stores:\n",
    "        for dept in depts:\n",
    "            for year in years:\n",
    "                #Find training and test data within same store and then same department\n",
    "                train = fold_train[(fold_train[\"Store\"] == store) & (fold_train[\"Dept\"] == dept) & (fold_train[\"Yr\"] == year)]\n",
    "                test = fold_test[(fold_test[\"Store\"] == store) & (fold_test[\"Dept\"] == dept) & (fold_test[\"Yr\"] == year)]\n",
    "\n",
    "                #abort if the train data is non-existant (i.e., this combo of store/dept doesnt appear in data)\n",
    "                if len(train) == 0:\n",
    "                    continue\n",
    "\n",
    "                Y_train = train[\"Weekly_Sales\"]\n",
    "                X_train = train.drop([\"Weekly_Sales\", \"Date\"], axis=1)\n",
    "\n",
    "                X_test = test\n",
    "\n",
    "                #Keep Store, dept, and date info for later merging\n",
    "                tmp_pred = X_test[['Store', 'Dept', 'Date']]\n",
    "                X_test = X_test.drop([\"Date\"], axis=1)\n",
    "\n",
    "                X_train = X_train.drop([\"Store\", \"Dept\", \"IsHoliday\"], axis=1)\n",
    "                X_test = X_test.drop([\"Store\", \"Dept\", \"IsHoliday\"], axis=1)\n",
    "\n",
    "                #Add intercept columns\n",
    "                X_train[\"Intercept\"] = 1\n",
    "                X_test[\"Intercept\"] = 1\n",
    "\n",
    "                #Cast one hot bools to ints\n",
    "                X_train = X_train.astype(int)\n",
    "                X_test = X_test.astype(int)\n",
    "\n",
    "                #Train model on only the features SVD selected\n",
    "                model = sm.OLS(Y_train, X_train).fit()\n",
    "                mycoef = model.params.fillna(0)\n",
    "                \n",
    "                #Predict Y\n",
    "                tmp_pred['Weekly_Pred'] = np.dot(X_test, mycoef)\n",
    "\n",
    "                #Readd context of store, dept, and date\n",
    "                test_pred = pd.concat([test_pred, tmp_pred], ignore_index=True)\n",
    "            \n",
    "        \n",
    "    test_pred['Weekly_Pred'].fillna(0, inplace=True)\n",
    "    # Save the output to CSV\n",
    "    file_path = f'Data/fold_{j+1}/mypred.csv'\n",
    "    print(f'fold_{j+1} processed')\n",
    "    test_pred.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Code (OLS only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OLS method requires a different preprocess function\n",
    "\n",
    "def preprocess(data):\n",
    "    #Split date into useful features\n",
    "    tmp = pd.to_datetime(data['Date'])\n",
    "    data['Wk'] = tmp.dt.isocalendar().week\n",
    "    data['Yr'] = tmp.dt.year\n",
    "    data['Wk'] = pd.Categorical(data['Wk'], categories=[i for i in range(1, 53)])  # 52 weeks \n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original OLS model\n",
    "\n",
    "# Loop over folds\n",
    "for j in range(n_datasets):\n",
    "    \n",
    "    # Get a pair of training and test sets\n",
    "    train = train_datasets[j]\n",
    "    test = test_datasets[j]\n",
    "\n",
    "    test_pred = pd.DataFrame()\n",
    "\n",
    "    # Identify the distinct store/dept pairs shared by the training and test set.\n",
    "    train_pairs = train[['Store', 'Dept']].drop_duplicates(ignore_index=True)\n",
    "    test_pairs = test[['Store', 'Dept']].drop_duplicates(ignore_index=True)\n",
    "    unique_pairs = pd.merge(train_pairs, test_pairs, how = 'inner', on =['Store', 'Dept'])\n",
    "\n",
    "    # Join the distinct store/dept pairs to the training set.\n",
    "    # Why left join? When would training data not be available?\n",
    "    train_split = unique_pairs.merge(train, on=['Store', 'Dept'], how='left')\n",
    "    \n",
    "    # Add numeric column for the year and a categorical column for week # to the training set\n",
    "    train_split = preprocess(train_split)\n",
    "    # Get design matrices for training y and X.\n",
    "    # y is just the target variable, Weekly_Sales.\n",
    "    # X has pivoted weeks, where individual weeks are separate 0/1 columns.\n",
    "    y, X = patsy.dmatrices('Weekly_Sales ~ Weekly_Sales + Store + Dept + Yr  + Wk', \n",
    "                        data = train_split, \n",
    "                        return_type='dataframe')\n",
    "    # Get dictionary where keys are (Store, Dept) tuples, and values are the\n",
    "    # \\\"Weekly_Sales + Store + Dept + Yr + Wk\\\" design matrices corresponding to each key.\n",
    "    # The design matrices include an Intercept column with value 1.\n",
    "    train_split = dict(tuple(X.groupby(['Store', 'Dept'])))\n",
    "\n",
    "    \n",
    "    # Now join the distinct store/dept pairs to the test set.\n",
    "    # Same question: why left join? When would training data not be available?\n",
    "    test_split = unique_pairs.merge(test, on=['Store', 'Dept'], how='left')\n",
    "    # Add numeric column for the year and a categorical column for week # to the test set\n",
    "    test_split = preprocess(test_split)\n",
    "    # Get design matrices for text y and X.\n",
    "    # y is the Year, and the design matrix is \\\"Store + Dept + Yr + Wk\\\".\n",
    "    # Note that test sets don't have the Weekly_Sales target variable.\n",
    "    # Why save Year as y?\n",
    "    y, X = patsy.dmatrices('Yr ~ Store + Dept + Yr  + Wk', \n",
    "                        data = test_split, \n",
    "                        return_type='dataframe')\n",
    "    # Re-add Date column to the design matrix X\n",
    "    X['Date'] = test_split['Date']\n",
    "    # Get dictionary where keys are (Store, Dept) tuples, and values are the\n",
    "    # \\\"Yr  + Wk + Date\\\" design matrices corresponding to each key.\n",
    "    test_split = dict(tuple(X.groupby(['Store', 'Dept'])))\n",
    "\n",
    "    # Get the training (store, dept) tuples.\n",
    "    # SHOULD be the same keys as in test, given the left joins above.\n",
    "    keys = list(train_split)\n",
    "\n",
    "    # Loop over (store, dept) tuples\n",
    "    for key in keys:\n",
    "        # Get training and test design matrices corresponding to (store, dept)\n",
    "        X_train = train_split[key]\n",
    "        X_test = test_split[key]\n",
    "    \n",
    "        # Target variable for (store, dept)\n",
    "        Y = X_train['Weekly_Sales']\n",
    "        # Drop ID and target to get just a table of predictors\n",
    "        X_train = X_train.drop(['Weekly_Sales','Store', 'Dept'], axis=1)\n",
    "        \n",
    "        # Identify columns that are all zero in training predictors, and drop them\n",
    "        # from both training and test X.\n",
    "        # This should drop weeks that are not represented in the training data.\n",
    "        # How does this affect test X? Are there cases where all test weeks would be dropped?\n",
    "        cols_to_drop = X_train.columns[(X_train == 0).all()]\n",
    "        X_train = X_train.drop(columns=cols_to_drop)\n",
    "        X_test = X_test.drop(columns=cols_to_drop)\n",
    "\n",
    "        \n",
    "        # Identify X training columns that are highly collinear with the columns to the left.\n",
    "        # Note that this doesn't check the Intercept column.\n",
    "        cols_to_drop = []\n",
    "        for i in range(len(X_train.columns) - 1, 1, -1):  # Start from the last column and move backward\n",
    "            col_name = X_train.columns[i]\n",
    "            # Extract the current column and all previous columns\n",
    "            tmp_Y = X_train.iloc[:, i].values\n",
    "            tmp_X = X_train.iloc[:, :i].values\n",
    "\n",
    "            coefficients, residuals, rank, s = np.linalg.lstsq(tmp_X, tmp_Y, rcond=None)\n",
    "            if np.sum(residuals) < 1e-10:\n",
    "                    cols_to_drop.append(col_name)\n",
    "                \n",
    "        # Drop those collinear columns from both training and test X.\n",
    "        X_train = X_train.drop(columns=cols_to_drop)\n",
    "        X_test = X_test.drop(columns=cols_to_drop)\n",
    "        print(X_train)\n",
    "        # Fit a regular ordinary least squares model on training Weekly_Sales.\n",
    "        model = sm.OLS(Y, X_train).fit()\n",
    "        mycoef = model.params.fillna(0)\n",
    "        \n",
    "        tmp_pred = X_test[['Store', 'Dept', 'Date']]\n",
    "        X_test = X_test.drop(['Store', 'Dept', 'Date'], axis=1)\n",
    "        \n",
    "        tmp_pred['Weekly_Pred'] = np.dot(X_test, mycoef)\n",
    "        test_pred = pd.concat([test_pred, tmp_pred], ignore_index=True)\n",
    "        \n",
    "    test_pred['Weekly_Pred'].fillna(0, inplace=True)\n",
    "    # Save the output to CSV\n",
    "    file_path = f'Data/fold_{j+1}/mypred.csv'\n",
    "    print(f'fold_{j+1} processed')\n",
    "    test_pred.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wae = wmae()\n",
    "for value in wae:\n",
    "    print(f\"\\t{value:.3f}\")\n",
    "print(f\"{sum(wae) / len(wae):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear errors\n",
    "\n",
    "\t2049.347\n",
    "\t1467.113\n",
    "\t1446.882\n",
    "\t1595.628\n",
    "\t2334.678\n",
    "\t1675.221\n",
    "\t1720.828\n",
    "\t1427.286\n",
    "\t1443.787\n",
    "\t1444.677\n",
    "1660.545"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit original OLS: group stores by year and add SVD/PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: (73, 45),\n",
       " 2: (73, 45),\n",
       " 3: (73, 45),\n",
       " 4: (73, 45),\n",
       " 5: (73, 45),\n",
       " 6: (73, 42),\n",
       " 7: (73, 45),\n",
       " 8: (73, 45),\n",
       " 9: (73, 45),\n",
       " 10: (73, 45),\n",
       " 11: (73, 45),\n",
       " 12: (73, 45),\n",
       " 13: (73, 45),\n",
       " 14: (73, 45),\n",
       " 16: (73, 45),\n",
       " 17: (73, 45),\n",
       " 18: (73, 37),\n",
       " 19: (73, 33),\n",
       " 20: (73, 45),\n",
       " 21: (73, 45),\n",
       " 22: (73, 41),\n",
       " 23: (73, 43),\n",
       " 24: (73, 41),\n",
       " 25: (73, 45),\n",
       " 26: (73, 43),\n",
       " 27: (73, 43),\n",
       " 28: (73, 43),\n",
       " 29: (73, 38),\n",
       " 30: (73, 37),\n",
       " 31: (73, 45),\n",
       " 32: (73, 41),\n",
       " 33: (73, 39),\n",
       " 34: (73, 39),\n",
       " 35: (73, 37),\n",
       " 36: (73, 37),\n",
       " 37: (73, 18),\n",
       " 38: (73, 45),\n",
       " 40: (73, 45),\n",
       " 41: (73, 40),\n",
       " 42: (73, 45),\n",
       " 43: (1, 1),\n",
       " 44: (73, 41),\n",
       " 45: (73, 28),\n",
       " 46: (73, 45),\n",
       " 47: (67, 18),\n",
       " 48: (73, 15),\n",
       " 49: (73, 33),\n",
       " 50: (73, 11),\n",
       " 51: (73, 20),\n",
       " 52: (73, 44),\n",
       " 54: (73, 37),\n",
       " 55: (73, 41),\n",
       " 56: (73, 43),\n",
       " 58: (73, 32),\n",
       " 59: (73, 45),\n",
       " 60: (73, 45),\n",
       " 65: (73, 1),\n",
       " 67: (73, 45),\n",
       " 71: (73, 38),\n",
       " 72: (73, 43),\n",
       " 74: (73, 45),\n",
       " 78: (22, 11),\n",
       " 79: (73, 45),\n",
       " 80: (73, 44),\n",
       " 81: (73, 45),\n",
       " 82: (73, 45),\n",
       " 83: (73, 41),\n",
       " 85: (73, 42),\n",
       " 87: (73, 45),\n",
       " 90: (73, 45),\n",
       " 91: (73, 45),\n",
       " 92: (73, 45),\n",
       " 93: (73, 41),\n",
       " 94: (73, 45),\n",
       " 95: (73, 45),\n",
       " 96: (73, 33),\n",
       " 97: (73, 44),\n",
       " 98: (73, 41),\n",
       " 99: (33, 20)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try on a single fold: j = 2\n",
    "j = 2\n",
    "\n",
    "# Components to return from SVD. This is from the example in Campuswire post #364:\n",
    "# https://campuswire.com/c/G06C55090/feed/364\n",
    "n_components = 8\n",
    "temp_seed = 4031\n",
    "    \n",
    "# Get a pair of training and test sets\n",
    "train = train_datasets[j]\n",
    "test = test_datasets[j]\n",
    "\n",
    "test_pred = pd.DataFrame()\n",
    "\n",
    "# Identify the distinct store/dept pairs shared by the training and test set.\n",
    "# Will only process these.\n",
    "\n",
    "train_pairs = train[['Store', 'Dept']].drop_duplicates(ignore_index=True)\n",
    "test_pairs = test[['Store', 'Dept']].drop_duplicates(ignore_index=True)\n",
    "unique_pairs = pd.merge(train_pairs, test_pairs, how = 'inner', on =['Store', 'Dept'])\n",
    "\n",
    "# Join the distinct store/dept pairs to the training set.\n",
    "# Why left join? When would training data not be available?\n",
    "train_split = unique_pairs.merge(train, on=['Store', 'Dept'], how='left')\n",
    "\n",
    "# Prep train data for SVD/PCA.\n",
    "# For each department, construct a dataframe consisting of:\n",
    "# rows = dates; columns = store numbers; and values = weekly sales.\n",
    "\n",
    "# Get columns needed for SVD\n",
    "train_store_dept_date_sales = train_split[[\"Store\", \"Dept\", \"Date\", \"Weekly_Sales\"]]\n",
    "# Group by Dept. Create dict where key = Dept and value = dataframe of Store/Date/Weekly_Sales.\n",
    "train_split = dict(tuple(train_store_dept_date_sales.groupby([\"Dept\"])))\n",
    "\n",
    "# Pivot each department's dataframe so that sales dates are rows and stores are columns, with values = Weekly_Sales.\n",
    "# Fill in missing values with zeroes.\n",
    "train_split = {dept:df.drop(columns=[\"Dept\"]).pivot(index=\"Date\", columns=\"Store\", values=\"Weekly_Sales\").reset_index().fillna(0) \\\n",
    "               for dept, df in train_split.items()}\n",
    "# Split sales dates out from remaining data\n",
    "train_sales_dates = {dept:df.Date for dept, df in train_split.items()}\n",
    "# Get just the sales figures for each dept\n",
    "train_X = {dept:df.drop(columns=[\"Date\"]) for dept, df in train_split.items()}\n",
    "\n",
    "#train_X[1]\n",
    "{dept:df.shape for dept, df in train_X.items()}\n",
    "\n",
    "# Perform SVD and choose the n_components most influential components.\n",
    "#svd = TruncatedSVD(n_components=n_components, random_state=temp_seed)\n",
    "#svd.fit_transform(train_X[1])\n",
    "# Collect dict of reduced-dimension training data, one entry per department.\n",
    "#svd_dict = {dept:svd.fit_transform(df) for dept, df in train_X.items()}\n",
    "#svd_dict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Store</th>\n",
       "      <th>Date</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>50605.27</td>\n",
       "      <td>74661.16</td>\n",
       "      <td>17566.72</td>\n",
       "      <td>91481.24</td>\n",
       "      <td>11955.45</td>\n",
       "      <td>50810.04</td>\n",
       "      <td>21129.93</td>\n",
       "      <td>37550.10</td>\n",
       "      <td>24917.84</td>\n",
       "      <td>...</td>\n",
       "      <td>15606.15</td>\n",
       "      <td>16121.22</td>\n",
       "      <td>9601.89</td>\n",
       "      <td>52359.34</td>\n",
       "      <td>27089.38</td>\n",
       "      <td>43875.06</td>\n",
       "      <td>14983.84</td>\n",
       "      <td>22720.10</td>\n",
       "      <td>8577.33</td>\n",
       "      <td>38214.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-02-12</td>\n",
       "      <td>44682.74</td>\n",
       "      <td>65487.46</td>\n",
       "      <td>15177.30</td>\n",
       "      <td>85763.19</td>\n",
       "      <td>11794.51</td>\n",
       "      <td>46456.01</td>\n",
       "      <td>21635.61</td>\n",
       "      <td>35205.40</td>\n",
       "      <td>22488.29</td>\n",
       "      <td>...</td>\n",
       "      <td>15127.60</td>\n",
       "      <td>14419.56</td>\n",
       "      <td>10201.55</td>\n",
       "      <td>50874.07</td>\n",
       "      <td>25187.64</td>\n",
       "      <td>38415.81</td>\n",
       "      <td>14330.30</td>\n",
       "      <td>19942.01</td>\n",
       "      <td>8169.20</td>\n",
       "      <td>27384.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-02-19</td>\n",
       "      <td>47928.89</td>\n",
       "      <td>70853.58</td>\n",
       "      <td>15676.11</td>\n",
       "      <td>86570.21</td>\n",
       "      <td>11707.09</td>\n",
       "      <td>48127.95</td>\n",
       "      <td>21900.24</td>\n",
       "      <td>38435.19</td>\n",
       "      <td>22173.92</td>\n",
       "      <td>...</td>\n",
       "      <td>15244.69</td>\n",
       "      <td>15382.87</td>\n",
       "      <td>9700.21</td>\n",
       "      <td>56270.81</td>\n",
       "      <td>25082.06</td>\n",
       "      <td>39140.52</td>\n",
       "      <td>15024.70</td>\n",
       "      <td>23421.42</td>\n",
       "      <td>7951.32</td>\n",
       "      <td>39601.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-02-26</td>\n",
       "      <td>44292.87</td>\n",
       "      <td>64963.90</td>\n",
       "      <td>15112.23</td>\n",
       "      <td>84405.45</td>\n",
       "      <td>11452.33</td>\n",
       "      <td>46128.34</td>\n",
       "      <td>21804.64</td>\n",
       "      <td>34999.91</td>\n",
       "      <td>22311.77</td>\n",
       "      <td>...</td>\n",
       "      <td>15600.86</td>\n",
       "      <td>15354.55</td>\n",
       "      <td>10126.21</td>\n",
       "      <td>52825.12</td>\n",
       "      <td>24338.23</td>\n",
       "      <td>40876.97</td>\n",
       "      <td>14988.04</td>\n",
       "      <td>21550.61</td>\n",
       "      <td>8990.75</td>\n",
       "      <td>34421.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-03-05</td>\n",
       "      <td>48397.98</td>\n",
       "      <td>68428.64</td>\n",
       "      <td>16477.28</td>\n",
       "      <td>87922.48</td>\n",
       "      <td>11300.69</td>\n",
       "      <td>52939.75</td>\n",
       "      <td>21228.66</td>\n",
       "      <td>36528.11</td>\n",
       "      <td>23609.13</td>\n",
       "      <td>...</td>\n",
       "      <td>15170.52</td>\n",
       "      <td>15732.79</td>\n",
       "      <td>10863.06</td>\n",
       "      <td>56766.01</td>\n",
       "      <td>25673.66</td>\n",
       "      <td>41030.89</td>\n",
       "      <td>15018.05</td>\n",
       "      <td>22607.30</td>\n",
       "      <td>8581.43</td>\n",
       "      <td>34631.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2011-05-27</td>\n",
       "      <td>45072.11</td>\n",
       "      <td>64755.07</td>\n",
       "      <td>16396.82</td>\n",
       "      <td>93786.26</td>\n",
       "      <td>13005.92</td>\n",
       "      <td>49611.81</td>\n",
       "      <td>17519.49</td>\n",
       "      <td>34057.22</td>\n",
       "      <td>24921.08</td>\n",
       "      <td>...</td>\n",
       "      <td>13473.34</td>\n",
       "      <td>16890.99</td>\n",
       "      <td>10381.16</td>\n",
       "      <td>67898.16</td>\n",
       "      <td>25729.44</td>\n",
       "      <td>47129.05</td>\n",
       "      <td>15458.19</td>\n",
       "      <td>20831.05</td>\n",
       "      <td>9572.17</td>\n",
       "      <td>34991.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2011-06-03</td>\n",
       "      <td>47844.27</td>\n",
       "      <td>65848.98</td>\n",
       "      <td>18860.29</td>\n",
       "      <td>95548.42</td>\n",
       "      <td>13791.92</td>\n",
       "      <td>56378.34</td>\n",
       "      <td>19234.93</td>\n",
       "      <td>36601.08</td>\n",
       "      <td>27252.62</td>\n",
       "      <td>...</td>\n",
       "      <td>12261.35</td>\n",
       "      <td>16783.06</td>\n",
       "      <td>10552.41</td>\n",
       "      <td>74980.46</td>\n",
       "      <td>28477.20</td>\n",
       "      <td>50087.94</td>\n",
       "      <td>16478.75</td>\n",
       "      <td>20756.12</td>\n",
       "      <td>9038.64</td>\n",
       "      <td>32532.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2011-06-10</td>\n",
       "      <td>46363.93</td>\n",
       "      <td>66831.49</td>\n",
       "      <td>17134.57</td>\n",
       "      <td>93516.12</td>\n",
       "      <td>12687.22</td>\n",
       "      <td>53504.63</td>\n",
       "      <td>21561.66</td>\n",
       "      <td>35293.99</td>\n",
       "      <td>25906.82</td>\n",
       "      <td>...</td>\n",
       "      <td>12099.80</td>\n",
       "      <td>17710.99</td>\n",
       "      <td>11151.02</td>\n",
       "      <td>68460.66</td>\n",
       "      <td>25203.79</td>\n",
       "      <td>47687.31</td>\n",
       "      <td>16512.57</td>\n",
       "      <td>21112.52</td>\n",
       "      <td>9182.69</td>\n",
       "      <td>35991.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2011-06-17</td>\n",
       "      <td>42939.63</td>\n",
       "      <td>66648.26</td>\n",
       "      <td>16598.43</td>\n",
       "      <td>96510.39</td>\n",
       "      <td>12213.47</td>\n",
       "      <td>50712.17</td>\n",
       "      <td>21189.99</td>\n",
       "      <td>35512.57</td>\n",
       "      <td>26369.13</td>\n",
       "      <td>...</td>\n",
       "      <td>14355.82</td>\n",
       "      <td>16940.94</td>\n",
       "      <td>10567.89</td>\n",
       "      <td>68181.39</td>\n",
       "      <td>27118.87</td>\n",
       "      <td>47584.55</td>\n",
       "      <td>16380.41</td>\n",
       "      <td>21292.31</td>\n",
       "      <td>8810.27</td>\n",
       "      <td>36629.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2011-06-24</td>\n",
       "      <td>42415.81</td>\n",
       "      <td>61507.28</td>\n",
       "      <td>16371.62</td>\n",
       "      <td>90050.58</td>\n",
       "      <td>11739.48</td>\n",
       "      <td>49046.48</td>\n",
       "      <td>24064.38</td>\n",
       "      <td>35052.46</td>\n",
       "      <td>24719.64</td>\n",
       "      <td>...</td>\n",
       "      <td>13109.57</td>\n",
       "      <td>17121.65</td>\n",
       "      <td>10414.89</td>\n",
       "      <td>67846.18</td>\n",
       "      <td>27242.19</td>\n",
       "      <td>46664.95</td>\n",
       "      <td>16037.26</td>\n",
       "      <td>19817.43</td>\n",
       "      <td>9172.96</td>\n",
       "      <td>34571.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Store        Date         1         2         3         4         5         6  \\\n",
       "0      2010-02-05  50605.27  74661.16  17566.72  91481.24  11955.45  50810.04   \n",
       "1      2010-02-12  44682.74  65487.46  15177.30  85763.19  11794.51  46456.01   \n",
       "2      2010-02-19  47928.89  70853.58  15676.11  86570.21  11707.09  48127.95   \n",
       "3      2010-02-26  44292.87  64963.90  15112.23  84405.45  11452.33  46128.34   \n",
       "4      2010-03-05  48397.98  68428.64  16477.28  87922.48  11300.69  52939.75   \n",
       "..            ...       ...       ...       ...       ...       ...       ...   \n",
       "68     2011-05-27  45072.11  64755.07  16396.82  93786.26  13005.92  49611.81   \n",
       "69     2011-06-03  47844.27  65848.98  18860.29  95548.42  13791.92  56378.34   \n",
       "70     2011-06-10  46363.93  66831.49  17134.57  93516.12  12687.22  53504.63   \n",
       "71     2011-06-17  42939.63  66648.26  16598.43  96510.39  12213.47  50712.17   \n",
       "72     2011-06-24  42415.81  61507.28  16371.62  90050.58  11739.48  49046.48   \n",
       "\n",
       "Store         7         8         9  ...        36        37        38  \\\n",
       "0      21129.93  37550.10  24917.84  ...  15606.15  16121.22   9601.89   \n",
       "1      21635.61  35205.40  22488.29  ...  15127.60  14419.56  10201.55   \n",
       "2      21900.24  38435.19  22173.92  ...  15244.69  15382.87   9700.21   \n",
       "3      21804.64  34999.91  22311.77  ...  15600.86  15354.55  10126.21   \n",
       "4      21228.66  36528.11  23609.13  ...  15170.52  15732.79  10863.06   \n",
       "..          ...       ...       ...  ...       ...       ...       ...   \n",
       "68     17519.49  34057.22  24921.08  ...  13473.34  16890.99  10381.16   \n",
       "69     19234.93  36601.08  27252.62  ...  12261.35  16783.06  10552.41   \n",
       "70     21561.66  35293.99  25906.82  ...  12099.80  17710.99  11151.02   \n",
       "71     21189.99  35512.57  26369.13  ...  14355.82  16940.94  10567.89   \n",
       "72     24064.38  35052.46  24719.64  ...  13109.57  17121.65  10414.89   \n",
       "\n",
       "Store        39        40        41        42        43       44        45  \n",
       "0      52359.34  27089.38  43875.06  14983.84  22720.10  8577.33  38214.01  \n",
       "1      50874.07  25187.64  38415.81  14330.30  19942.01  8169.20  27384.43  \n",
       "2      56270.81  25082.06  39140.52  15024.70  23421.42  7951.32  39601.72  \n",
       "3      52825.12  24338.23  40876.97  14988.04  21550.61  8990.75  34421.20  \n",
       "4      56766.01  25673.66  41030.89  15018.05  22607.30  8581.43  34631.06  \n",
       "..          ...       ...       ...       ...       ...      ...       ...  \n",
       "68     67898.16  25729.44  47129.05  15458.19  20831.05  9572.17  34991.20  \n",
       "69     74980.46  28477.20  50087.94  16478.75  20756.12  9038.64  32532.02  \n",
       "70     68460.66  25203.79  47687.31  16512.57  21112.52  9182.69  35991.25  \n",
       "71     68181.39  27118.87  47584.55  16380.41  21292.31  8810.27  36629.18  \n",
       "72     67846.18  27242.19  46664.95  16037.26  19817.43  9172.96  34571.54  \n",
       "\n",
       "[73 rows x 46 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_split[2].drop(columns=[\"Dept\"]).pivot(index=\"Date\", columns=\"Store\", values=\"Weekly_Sales\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Store</th>\n",
       "      <th>Date</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>24924.50</td>\n",
       "      <td>35034.06</td>\n",
       "      <td>6453.58</td>\n",
       "      <td>38724.42</td>\n",
       "      <td>9323.89</td>\n",
       "      <td>25619.00</td>\n",
       "      <td>8970.97</td>\n",
       "      <td>16181.89</td>\n",
       "      <td>12861.40</td>\n",
       "      <td>...</td>\n",
       "      <td>2144.48</td>\n",
       "      <td>11283.23</td>\n",
       "      <td>6732.38</td>\n",
       "      <td>21244.50</td>\n",
       "      <td>18116.85</td>\n",
       "      <td>16971.05</td>\n",
       "      <td>10425.77</td>\n",
       "      <td>6476.76</td>\n",
       "      <td>6871.20</td>\n",
       "      <td>18628.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-02-12</td>\n",
       "      <td>46039.49</td>\n",
       "      <td>60483.70</td>\n",
       "      <td>12748.72</td>\n",
       "      <td>69872.44</td>\n",
       "      <td>16861.10</td>\n",
       "      <td>43749.81</td>\n",
       "      <td>14026.65</td>\n",
       "      <td>34262.09</td>\n",
       "      <td>20273.94</td>\n",
       "      <td>...</td>\n",
       "      <td>4091.72</td>\n",
       "      <td>16184.33</td>\n",
       "      <td>9132.55</td>\n",
       "      <td>39584.16</td>\n",
       "      <td>26138.18</td>\n",
       "      <td>30204.01</td>\n",
       "      <td>15725.68</td>\n",
       "      <td>18597.64</td>\n",
       "      <td>12315.65</td>\n",
       "      <td>22416.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-02-19</td>\n",
       "      <td>41595.55</td>\n",
       "      <td>58221.52</td>\n",
       "      <td>8918.31</td>\n",
       "      <td>49937.09</td>\n",
       "      <td>11417.67</td>\n",
       "      <td>34750.82</td>\n",
       "      <td>12477.79</td>\n",
       "      <td>22319.25</td>\n",
       "      <td>14819.97</td>\n",
       "      <td>...</td>\n",
       "      <td>3101.57</td>\n",
       "      <td>10722.08</td>\n",
       "      <td>8045.28</td>\n",
       "      <td>23025.91</td>\n",
       "      <td>23172.75</td>\n",
       "      <td>20694.24</td>\n",
       "      <td>13300.99</td>\n",
       "      <td>9939.45</td>\n",
       "      <td>7751.11</td>\n",
       "      <td>28756.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-02-26</td>\n",
       "      <td>19403.54</td>\n",
       "      <td>25962.32</td>\n",
       "      <td>4992.00</td>\n",
       "      <td>30107.54</td>\n",
       "      <td>7168.41</td>\n",
       "      <td>19896.08</td>\n",
       "      <td>8602.73</td>\n",
       "      <td>11722.71</td>\n",
       "      <td>10530.98</td>\n",
       "      <td>...</td>\n",
       "      <td>1451.39</td>\n",
       "      <td>9256.03</td>\n",
       "      <td>5951.54</td>\n",
       "      <td>14011.39</td>\n",
       "      <td>14728.82</td>\n",
       "      <td>12816.16</td>\n",
       "      <td>9303.34</td>\n",
       "      <td>6460.56</td>\n",
       "      <td>6014.71</td>\n",
       "      <td>14656.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-03-05</td>\n",
       "      <td>21827.90</td>\n",
       "      <td>27372.05</td>\n",
       "      <td>5172.73</td>\n",
       "      <td>31580.69</td>\n",
       "      <td>8344.13</td>\n",
       "      <td>22839.36</td>\n",
       "      <td>9541.12</td>\n",
       "      <td>12979.74</td>\n",
       "      <td>10438.47</td>\n",
       "      <td>...</td>\n",
       "      <td>1510.25</td>\n",
       "      <td>9766.32</td>\n",
       "      <td>6485.19</td>\n",
       "      <td>14875.08</td>\n",
       "      <td>18494.41</td>\n",
       "      <td>15154.51</td>\n",
       "      <td>10244.26</td>\n",
       "      <td>6939.08</td>\n",
       "      <td>6120.60</td>\n",
       "      <td>16608.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2011-05-27</td>\n",
       "      <td>15741.60</td>\n",
       "      <td>21334.34</td>\n",
       "      <td>5194.21</td>\n",
       "      <td>25035.61</td>\n",
       "      <td>7901.75</td>\n",
       "      <td>16479.47</td>\n",
       "      <td>6616.65</td>\n",
       "      <td>8140.29</td>\n",
       "      <td>8687.90</td>\n",
       "      <td>...</td>\n",
       "      <td>1680.75</td>\n",
       "      <td>8491.25</td>\n",
       "      <td>5549.96</td>\n",
       "      <td>14700.37</td>\n",
       "      <td>13445.91</td>\n",
       "      <td>17880.00</td>\n",
       "      <td>9021.05</td>\n",
       "      <td>5584.23</td>\n",
       "      <td>7716.02</td>\n",
       "      <td>10632.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2011-06-03</td>\n",
       "      <td>16434.15</td>\n",
       "      <td>22174.12</td>\n",
       "      <td>4906.27</td>\n",
       "      <td>25401.86</td>\n",
       "      <td>8175.25</td>\n",
       "      <td>17836.28</td>\n",
       "      <td>7839.66</td>\n",
       "      <td>9182.01</td>\n",
       "      <td>9240.67</td>\n",
       "      <td>...</td>\n",
       "      <td>1810.76</td>\n",
       "      <td>8829.34</td>\n",
       "      <td>5496.54</td>\n",
       "      <td>16575.04</td>\n",
       "      <td>14579.85</td>\n",
       "      <td>16970.53</td>\n",
       "      <td>9004.52</td>\n",
       "      <td>6172.43</td>\n",
       "      <td>8044.30</td>\n",
       "      <td>11142.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2011-06-10</td>\n",
       "      <td>15883.52</td>\n",
       "      <td>21554.22</td>\n",
       "      <td>4790.03</td>\n",
       "      <td>24726.22</td>\n",
       "      <td>8170.13</td>\n",
       "      <td>18069.27</td>\n",
       "      <td>7728.34</td>\n",
       "      <td>8570.93</td>\n",
       "      <td>8963.92</td>\n",
       "      <td>...</td>\n",
       "      <td>1816.06</td>\n",
       "      <td>9983.83</td>\n",
       "      <td>5555.61</td>\n",
       "      <td>14498.75</td>\n",
       "      <td>13945.42</td>\n",
       "      <td>17552.61</td>\n",
       "      <td>9408.68</td>\n",
       "      <td>5450.76</td>\n",
       "      <td>7632.33</td>\n",
       "      <td>10312.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2011-06-17</td>\n",
       "      <td>14978.09</td>\n",
       "      <td>22431.56</td>\n",
       "      <td>5738.30</td>\n",
       "      <td>27152.27</td>\n",
       "      <td>8157.72</td>\n",
       "      <td>17045.25</td>\n",
       "      <td>7781.62</td>\n",
       "      <td>9379.33</td>\n",
       "      <td>8638.83</td>\n",
       "      <td>...</td>\n",
       "      <td>1828.68</td>\n",
       "      <td>9502.31</td>\n",
       "      <td>5022.86</td>\n",
       "      <td>14906.77</td>\n",
       "      <td>14417.44</td>\n",
       "      <td>17648.40</td>\n",
       "      <td>8472.14</td>\n",
       "      <td>5580.68</td>\n",
       "      <td>7580.63</td>\n",
       "      <td>11742.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2011-06-24</td>\n",
       "      <td>15682.81</td>\n",
       "      <td>21426.72</td>\n",
       "      <td>4484.47</td>\n",
       "      <td>26859.67</td>\n",
       "      <td>8392.34</td>\n",
       "      <td>19347.14</td>\n",
       "      <td>8561.67</td>\n",
       "      <td>8113.01</td>\n",
       "      <td>8651.38</td>\n",
       "      <td>...</td>\n",
       "      <td>1533.18</td>\n",
       "      <td>9345.12</td>\n",
       "      <td>5126.79</td>\n",
       "      <td>13960.26</td>\n",
       "      <td>15092.44</td>\n",
       "      <td>18820.51</td>\n",
       "      <td>8533.29</td>\n",
       "      <td>5696.96</td>\n",
       "      <td>7377.88</td>\n",
       "      <td>11570.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Store        Date         1         2         3         4         5         6  \\\n",
       "0      2010-02-05  24924.50  35034.06   6453.58  38724.42   9323.89  25619.00   \n",
       "1      2010-02-12  46039.49  60483.70  12748.72  69872.44  16861.10  43749.81   \n",
       "2      2010-02-19  41595.55  58221.52   8918.31  49937.09  11417.67  34750.82   \n",
       "3      2010-02-26  19403.54  25962.32   4992.00  30107.54   7168.41  19896.08   \n",
       "4      2010-03-05  21827.90  27372.05   5172.73  31580.69   8344.13  22839.36   \n",
       "..            ...       ...       ...       ...       ...       ...       ...   \n",
       "68     2011-05-27  15741.60  21334.34   5194.21  25035.61   7901.75  16479.47   \n",
       "69     2011-06-03  16434.15  22174.12   4906.27  25401.86   8175.25  17836.28   \n",
       "70     2011-06-10  15883.52  21554.22   4790.03  24726.22   8170.13  18069.27   \n",
       "71     2011-06-17  14978.09  22431.56   5738.30  27152.27   8157.72  17045.25   \n",
       "72     2011-06-24  15682.81  21426.72   4484.47  26859.67   8392.34  19347.14   \n",
       "\n",
       "Store         7         8         9  ...       36        37       38  \\\n",
       "0       8970.97  16181.89  12861.40  ...  2144.48  11283.23  6732.38   \n",
       "1      14026.65  34262.09  20273.94  ...  4091.72  16184.33  9132.55   \n",
       "2      12477.79  22319.25  14819.97  ...  3101.57  10722.08  8045.28   \n",
       "3       8602.73  11722.71  10530.98  ...  1451.39   9256.03  5951.54   \n",
       "4       9541.12  12979.74  10438.47  ...  1510.25   9766.32  6485.19   \n",
       "..          ...       ...       ...  ...      ...       ...      ...   \n",
       "68      6616.65   8140.29   8687.90  ...  1680.75   8491.25  5549.96   \n",
       "69      7839.66   9182.01   9240.67  ...  1810.76   8829.34  5496.54   \n",
       "70      7728.34   8570.93   8963.92  ...  1816.06   9983.83  5555.61   \n",
       "71      7781.62   9379.33   8638.83  ...  1828.68   9502.31  5022.86   \n",
       "72      8561.67   8113.01   8651.38  ...  1533.18   9345.12  5126.79   \n",
       "\n",
       "Store        39        40        41        42        43        44        45  \n",
       "0      21244.50  18116.85  16971.05  10425.77   6476.76   6871.20  18628.11  \n",
       "1      39584.16  26138.18  30204.01  15725.68  18597.64  12315.65  22416.94  \n",
       "2      23025.91  23172.75  20694.24  13300.99   9939.45   7751.11  28756.53  \n",
       "3      14011.39  14728.82  12816.16   9303.34   6460.56   6014.71  14656.08  \n",
       "4      14875.08  18494.41  15154.51  10244.26   6939.08   6120.60  16608.87  \n",
       "..          ...       ...       ...       ...       ...       ...       ...  \n",
       "68     14700.37  13445.91  17880.00   9021.05   5584.23   7716.02  10632.88  \n",
       "69     16575.04  14579.85  16970.53   9004.52   6172.43   8044.30  11142.70  \n",
       "70     14498.75  13945.42  17552.61   9408.68   5450.76   7632.33  10312.84  \n",
       "71     14906.77  14417.44  17648.40   8472.14   5580.68   7580.63  11742.00  \n",
       "72     13960.26  15092.44  18820.51   8533.29   5696.96   7377.88  11570.03  \n",
       "\n",
       "[73 rows x 46 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pivot each department's dataframe so that sales dates are rows and stores are columns, with values = Weekly_Sales\n",
    "train_split = {dept:df.drop(columns=[\"Dept\"]).pivot(index=\"Date\", columns=\"Store\", values=\"Weekly_Sales\").reset_index() \\\n",
    "               for dept, df in train_split.items()}\n",
    "train_split[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Store</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41057.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39799.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42908.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40515.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49353.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>46790.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>43607.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>39256.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>38254.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>39678.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Store        34\n",
       "0      41057.25\n",
       "1      39799.36\n",
       "2      42908.44\n",
       "3      40515.35\n",
       "4      49353.20\n",
       "..          ...\n",
       "68     46790.83\n",
       "69     43607.42\n",
       "70     39256.49\n",
       "71     38254.73\n",
       "72     39678.65\n",
       "\n",
       "[73 rows x 1 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scratch_X = train_X[65]\n",
    "scratch_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Store</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41057.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39799.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42908.44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40515.35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49353.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>46790.83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>43607.42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>39256.49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>38254.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>39678.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Store        34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49\n",
       "0      41057.25   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "1      39799.36   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "2      42908.44   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "3      40515.35   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "4      49353.20   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "..          ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..\n",
       "68     46790.83   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "69     43607.42   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "70     39256.49   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "71     38254.73   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "72     39678.65   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "\n",
       "[73 rows x 16 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(35, 50):\n",
    "    scratch_X[str(i)] = 0\n",
    "    \n",
    "scratch_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.48807268e+05, -9.99353517e+03, -3.18608963e+01,\n",
       "        -4.37803668e+03, -2.67268940e+03, -3.67391331e+03,\n",
       "        -3.71424484e+03, -1.91465438e+03],\n",
       "       [ 2.41045082e+05, -3.02587043e+04,  1.69425699e+04,\n",
       "         1.30125058e+04,  7.44887881e+03, -1.43381733e+04,\n",
       "        -6.22495960e+03,  4.44900402e+03],\n",
       "       [ 1.84280398e+05, -2.67636306e+04,  1.77219628e+04,\n",
       "        -1.38735259e+04, -7.91462081e+03, -8.82273176e+03,\n",
       "        -8.56182600e+03, -1.38090735e+02],\n",
       "       [ 1.12611339e+05, -1.28745480e+04,  6.13199188e+01,\n",
       "        -4.78428038e+03, -7.68655354e+03, -1.06196543e+02,\n",
       "         2.69388836e+03,  1.27912358e+03],\n",
       "       [ 1.26443571e+05, -9.42570471e+03, -1.85355589e+03,\n",
       "        -6.87753006e+03, -9.43867658e+03, -6.61670766e+02,\n",
       "         9.00026200e+02,  1.90892115e+03],\n",
       "       [ 1.35863547e+05, -2.56713770e+03, -5.22163212e+03,\n",
       "        -8.46320284e+03, -5.94078955e+03, -5.81386135e+02,\n",
       "        -7.32659014e+02, -2.34759150e+03],\n",
       "       [ 1.45204659e+05,  3.42046684e+03, -7.14075980e+03,\n",
       "        -8.02701808e+03, -6.93745173e+03, -2.77004958e+03,\n",
       "         6.28796758e+02, -5.96824320e+03],\n",
       "       [ 1.81420275e+05,  1.54266905e+04, -4.31060079e+03,\n",
       "        -1.01290401e+04, -1.16682934e+03,  2.07508214e+03,\n",
       "        -2.33844521e+02, -5.33525959e+03],\n",
       "       [ 4.37471268e+05,  7.55554305e+04,  7.21529877e+03,\n",
       "        -2.72584610e+04, -4.69699384e+03, -1.14003328e+03,\n",
       "        -1.07447692e+04,  4.14125902e+03],\n",
       "       [ 2.60331378e+05,  4.41390797e+03,  4.61709826e+04,\n",
       "        -1.35906753e+04, -1.19179325e+04,  7.08032204e+03,\n",
       "        -2.65645793e+03, -2.32078680e+03],\n",
       "       [ 1.00058585e+05, -1.21376989e+04,  3.72529371e+02,\n",
       "        -4.80434781e+03, -4.61708390e+03,  3.28027603e+03,\n",
       "        -3.18819774e+03,  1.19141649e+03],\n",
       "       [ 9.59324168e+04, -1.30658320e+04, -1.45159325e+03,\n",
       "        -2.40996500e+03, -3.87122776e+03,  1.99405803e+03,\n",
       "        -2.37432688e+03, -7.50421740e+02],\n",
       "       [ 9.82712426e+04, -1.29501434e+04, -2.74609399e+03,\n",
       "        -3.20076208e+03, -4.16330596e+03,  6.37468206e+02,\n",
       "        -1.66553044e+03, -4.75299638e+02],\n",
       "       [ 1.10125508e+05, -1.43882530e+04, -3.26288358e+03,\n",
       "        -1.18828440e+03, -3.26019847e+03,  8.85667630e+02,\n",
       "        -4.34705620e+02, -2.29864095e+03],\n",
       "       [ 1.10086155e+05, -1.36761219e+04, -3.78678969e+03,\n",
       "        -1.83983515e+03, -4.01042166e+03, -1.55460238e+02,\n",
       "        -1.07861780e+03, -1.19911430e+03],\n",
       "       [ 1.04648091e+05, -1.09026546e+04, -5.44715480e+03,\n",
       "        -4.60128321e+02, -1.94227609e+03,  1.90486529e+03,\n",
       "        -1.38509431e+03, -5.13405022e+02],\n",
       "       [ 1.06775349e+05, -1.04916536e+04, -6.12984088e+03,\n",
       "         5.03049583e+02, -1.96940144e+03,  1.54855369e+03,\n",
       "        -1.20812375e+03, -3.69518128e+03],\n",
       "       [ 1.07060377e+05, -1.20265822e+04, -4.99578205e+03,\n",
       "        -3.03656397e+03, -2.78051806e+03, -3.11851707e+01,\n",
       "        -9.74110763e+02, -2.86873697e+03],\n",
       "       [ 1.07238158e+05, -1.14930320e+04, -6.79928798e+03,\n",
       "        -5.19925526e+03, -2.64149316e+03, -6.12127765e+02,\n",
       "        -2.29242343e+03, -2.05224485e+03],\n",
       "       [ 1.10584701e+05, -9.72582918e+03, -7.21882528e+03,\n",
       "        -2.80297297e+03, -1.08993825e+03,  8.05225538e+02,\n",
       "        -3.15827605e+03, -3.42318978e+03],\n",
       "       [ 1.07405793e+05, -9.81080521e+03, -5.93558006e+03,\n",
       "        -2.62755310e+03, -1.17546560e+03,  1.61923616e+02,\n",
       "        -2.29886008e+03, -4.83198412e+03],\n",
       "       [ 1.12033034e+05, -1.02520881e+04, -8.44429209e+03,\n",
       "        -3.53191434e+03, -2.22457101e+03, -7.12364408e+01,\n",
       "        -3.35427068e+03, -3.94608226e+03],\n",
       "       [ 1.04053380e+05, -1.45222180e+04, -3.48083112e+03,\n",
       "        -5.07542935e+03, -2.44297314e+03, -4.97001151e+02,\n",
       "        -1.99488636e+03, -5.54263467e+03],\n",
       "       [ 1.06743049e+05, -1.28200470e+04, -7.34061804e+03,\n",
       "        -3.52069333e+03, -2.37408483e+03, -6.30499551e+02,\n",
       "        -3.45953807e+03, -4.05840293e+03],\n",
       "       [ 1.04066153e+05, -1.15927389e+04, -7.18718679e+03,\n",
       "        -2.61222151e+03, -6.36241151e+02,  9.62848855e+02,\n",
       "        -1.79652668e+03, -3.83506005e+03],\n",
       "       [ 1.04572145e+05, -1.29459112e+04, -6.75814690e+03,\n",
       "        -4.06094554e+03, -3.75566709e+03,  1.63615336e+03,\n",
       "        -2.87975958e+03, -3.23597937e+03],\n",
       "       [ 1.05647094e+05, -1.23950128e+04, -5.92976877e+03,\n",
       "        -3.52277787e+03, -3.96694268e+03,  1.04221250e+03,\n",
       "        -2.60196792e+03, -3.97100069e+03],\n",
       "       [ 1.03443427e+05, -1.16963812e+04, -7.18231554e+03,\n",
       "        -3.07076885e+03, -3.42502572e+03,  4.97742062e+02,\n",
       "        -2.46913688e+03, -1.07932600e+03],\n",
       "       [ 1.01223485e+05, -1.18343402e+04, -6.97788892e+03,\n",
       "        -1.00461111e+03, -2.45164458e+03,  8.28866867e+02,\n",
       "        -3.15098105e+03, -1.00440298e+03],\n",
       "       [ 1.00380578e+05, -1.16420007e+04, -6.83052080e+03,\n",
       "        -2.92149780e+03, -1.25679578e+01,  8.17727866e+02,\n",
       "        -1.90376208e+03,  1.32171187e+03],\n",
       "       [ 1.07180207e+05, -1.47244867e+04, -6.92787256e+03,\n",
       "        -5.97318794e+02, -1.50817648e+03, -2.96917229e+02,\n",
       "         8.33168269e+02,  2.93893748e+03],\n",
       "       [ 1.11846763e+05, -1.47902805e+04, -7.53937300e+03,\n",
       "        -4.72182058e+03, -2.85353240e+02, -2.03205440e+03,\n",
       "        -1.46484843e+03,  2.37752572e+03],\n",
       "       [ 1.16934886e+05, -1.32109426e+04, -5.83328047e+03,\n",
       "        -2.97266676e+03,  1.97140625e+03, -1.56227576e+02,\n",
       "         4.42258229e+02,  4.42377126e+03],\n",
       "       [ 1.16809922e+05, -1.37555501e+04, -5.35765971e+03,\n",
       "        -2.30549637e+03,  1.96203155e+03,  1.88609631e+03,\n",
       "         9.50256038e+02,  1.92257750e+03],\n",
       "       [ 1.26574013e+05, -1.35595977e+04, -6.85861384e+03,\n",
       "        -3.75428964e+03,  1.96648630e+03,  2.00626993e+03,\n",
       "         3.43611448e+03,  3.44354101e+03],\n",
       "       [ 1.48078074e+05, -1.11927567e+04, -7.52384682e+03,\n",
       "        -4.16698613e+03,  9.75970643e+02,  3.21627088e+03,\n",
       "         1.58778430e+03,  1.84629502e+03],\n",
       "       [ 1.66085397e+05, -7.69607995e+03, -9.88424125e+03,\n",
       "        -2.23105377e+03,  3.71042948e+03,  1.52011309e+03,\n",
       "         1.96896509e+02,  3.24992925e+03],\n",
       "       [ 1.93962337e+05, -1.00353965e+03, -9.78428731e+03,\n",
       "         7.28866214e+02,  8.99971083e+03,  4.19978519e+03,\n",
       "        -5.06491632e+03,  6.87807346e+03],\n",
       "       [ 3.02344071e+05,  1.19459102e+04,  2.46042859e+02,\n",
       "         2.81591049e+03,  3.50888195e+04,  1.21430390e+04,\n",
       "        -8.75776762e+03, -6.37148829e+03],\n",
       "       [ 2.18221345e+05, -1.62600614e+04,  2.32366015e+04,\n",
       "        -8.92183883e+03,  9.71320972e+03,  1.98592435e+04,\n",
       "         8.24191751e+03,  3.87124279e+03],\n",
       "       [ 1.05548378e+05, -1.26683146e+04, -2.73952194e+03,\n",
       "        -5.31329880e+03, -4.17733569e+03, -2.39802493e+02,\n",
       "        -2.13546819e+01,  4.80831471e+03],\n",
       "       [ 1.14440298e+05, -9.69517019e+03, -4.11766353e+03,\n",
       "        -2.91633943e+03, -3.19287138e+03,  2.06643948e+02,\n",
       "         1.45499397e+03,  7.30544322e+03],\n",
       "       [ 1.21719648e+05, -9.01699987e+03, -5.21111383e+03,\n",
       "        -9.10403993e+02,  1.27731724e+03,  3.70097613e+03,\n",
       "        -1.83902308e+03,  3.01661840e+03],\n",
       "       [ 1.59696657e+05, -3.12098734e+03, -5.57540585e+03,\n",
       "        -3.31827733e+03, -3.51014538e+03,  4.22297137e+03,\n",
       "         2.93157003e+03,  6.50949576e+03],\n",
       "       [ 2.24422509e+05,  5.75778718e+03, -1.05276857e+04,\n",
       "         1.88797436e+03, -8.45548098e+03,  5.23490108e+03,\n",
       "         3.84337393e+03,  8.72171717e+03],\n",
       "       [ 3.13895711e+05,  1.12350120e+04, -1.13016510e+04,\n",
       "         2.79374711e+04, -3.74811894e+03,  3.93676106e+02,\n",
       "        -5.71130000e+02,  9.52954001e+03],\n",
       "       [ 4.01363394e+05,  3.42605457e+04, -4.95629875e+03,\n",
       "         5.01812926e+04, -1.43583439e+04,  5.60680435e+03,\n",
       "        -7.68558747e+03, -3.86140702e+03],\n",
       "       [ 1.02449927e+05, -1.58715166e+04,  5.77134086e+03,\n",
       "         6.65636188e+02, -6.97096847e+03,  5.99322251e+02,\n",
       "        -1.55471791e+02,  2.82635671e+03],\n",
       "       [ 8.51413419e+04, -1.43354172e+04, -4.82711199e+02,\n",
       "        -7.86295967e+02, -2.64053769e+03,  1.04176074e+03,\n",
       "         2.33393563e+03,  1.69437270e+03],\n",
       "       [ 9.29869010e+04, -1.61484121e+04, -1.40676500e+03,\n",
       "         2.85875430e+02, -1.42376842e+03, -1.52094511e+03,\n",
       "         3.10083186e+03,  1.99418334e+03],\n",
       "       [ 1.02565734e+05, -1.32168693e+04, -1.96370510e+03,\n",
       "         4.02149170e+03,  8.80469217e+02, -7.01747259e+02,\n",
       "         2.34239842e+03,  1.33152217e+03],\n",
       "       [ 1.06820272e+05, -1.39035553e+04, -1.89520736e+03,\n",
       "         2.87050049e+03,  1.94396701e+03, -1.61937085e+03,\n",
       "         1.70293193e+03,  6.18182487e+02],\n",
       "       [ 1.31639908e+05, -9.48333809e+03, -1.42062591e+03,\n",
       "        -1.31334793e+03,  3.38319202e+03, -1.97415801e+03,\n",
       "         4.21764183e+03,  2.26186854e+02],\n",
       "       [ 2.01693202e+05, -1.70745568e+04,  5.66844281e+03,\n",
       "         5.86199528e+03,  1.20115615e+04, -1.20466306e+04,\n",
       "        -3.40884322e+03,  4.71593650e+03],\n",
       "       [ 2.38372950e+05, -3.06524254e+04,  3.25994232e+04,\n",
       "         8.85241121e+03,  1.41398288e+04, -7.52733720e+03,\n",
       "         2.48824543e+02,  5.78481923e+02],\n",
       "       [ 1.00305408e+05, -1.34371993e+04, -5.29870072e+02,\n",
       "        -6.30559006e+02,  1.33997000e+03, -8.44533411e+01,\n",
       "         1.88432338e+03, -1.84243348e+02],\n",
       "       [ 1.10754344e+05, -1.38713126e+04, -8.46823705e+02,\n",
       "        -4.95343185e+03, -1.69187188e+03,  1.35134085e+03,\n",
       "         3.75406221e+03,  1.65255476e+03],\n",
       "       [ 1.15697155e+05, -1.28419855e+04, -9.87582516e+02,\n",
       "        -2.17094520e+03,  6.16199724e+02, -1.71469561e+03,\n",
       "         3.66178257e+03, -1.62367072e+03],\n",
       "       [ 1.20212428e+05, -9.41537926e+03, -4.36454706e+03,\n",
       "        -2.87536234e+03,  8.52860054e+02, -2.85618415e+03,\n",
       "         3.76278871e+03, -6.56027742e+02],\n",
       "       [ 1.23124955e+05, -4.56109195e+03, -4.80958810e+03,\n",
       "        -7.17042452e+02,  2.93741500e+03, -1.66507798e+03,\n",
       "         6.33151391e+03, -2.22499982e+03],\n",
       "       [ 1.31967655e+05, -2.32690249e+03, -6.82620341e+03,\n",
       "        -1.50124733e+03,  3.15687002e+03, -2.89055536e+03,\n",
       "         7.05690582e+03, -3.52867773e+03],\n",
       "       [ 1.58156980e+05,  5.21264275e+03, -7.36968840e+03,\n",
       "        -8.22532737e+03,  9.81444587e+02, -1.50393308e+03,\n",
       "         6.31453935e+03, -1.55763282e+03],\n",
       "       [ 1.97663361e+05,  1.70551157e+04, -8.93385335e+03,\n",
       "        -8.18355297e+03,  2.78166054e+03, -3.64148139e+03,\n",
       "         9.66952068e+03,  2.62334480e+03],\n",
       "       [ 4.13605844e+05,  7.29489513e+04, -6.71638128e+03,\n",
       "        -7.77475975e+03,  9.08439969e+03, -1.21917758e+04,\n",
       "         9.61318478e+03, -2.48250453e+03],\n",
       "       [ 2.56478568e+05,  8.15624152e+03,  3.04089116e+04,\n",
       "         1.81043425e+04, -1.10656309e+04,  4.92871779e+02,\n",
       "         1.38629630e+04, -6.65129917e+03],\n",
       "       [ 1.06335237e+05, -1.21025554e+04,  8.36978704e+02,\n",
       "         2.43625163e+03, -2.70257386e+03,  1.44699781e+01,\n",
       "         3.39305726e+03, -1.18641509e+03],\n",
       "       [ 1.00249813e+05, -1.31747583e+04, -2.11064423e+03,\n",
       "         2.86789721e+03, -1.34394083e+02, -1.11916039e+01,\n",
       "         2.62792948e+03, -2.38554101e+03],\n",
       "       [ 9.59260287e+04, -1.31188524e+04, -3.92622347e+03,\n",
       "         1.04011500e+03,  2.35991896e+03,  1.69917960e+03,\n",
       "         1.84772994e+03, -1.57970534e+03],\n",
       "       [ 9.77629197e+04, -1.15959012e+04, -6.06142093e+03,\n",
       "         2.05891162e+03,  3.15229488e+03,  4.29045432e+02,\n",
       "         1.84528097e+03, -3.15658211e+03],\n",
       "       [ 9.81137033e+04, -1.37092570e+04, -4.41935203e+03,\n",
       "         3.25887444e+03,  2.04043170e+03, -6.90663960e+02,\n",
       "         2.32338986e+03, -4.67413586e+03],\n",
       "       [ 9.88991402e+04, -1.30373058e+04, -4.82713717e+03,\n",
       "         6.91947179e+02,  6.29062862e+02,  8.78144235e+02,\n",
       "         3.14475278e+03, -4.98505718e+03],\n",
       "       [ 1.01941236e+05, -1.07614131e+04, -7.10662885e+03,\n",
       "         4.01897738e+03,  3.45836714e+03, -1.06001676e+03,\n",
       "         1.99588312e+03, -4.69692367e+03],\n",
       "       [ 1.03293218e+05, -1.07388841e+04, -7.32580508e+03,\n",
       "         2.97082434e+03,  2.78307340e+03, -4.49706680e+01,\n",
       "         8.78984933e+02, -5.90597958e+03]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=8, random_state=4031)\n",
    "svd.fit_transform(train_X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(svd == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
